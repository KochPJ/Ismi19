{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import pylab as plt\n",
    "import random\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dirs\n",
    "data_dir = './data/'\n",
    "train_dir_x = os.path.join(data_dir, 'camelyonpatch_level_2_split_train_x.h5')\n",
    "train_dir_y = os.path.join(data_dir, 'camelyonpatch_level_2_split_train_y.h5')\n",
    "\n",
    "learned = pd.read_csv(os.path.join(data_dir,'learned.csv'))\n",
    "learned_index = learned['learned']\n",
    "\n",
    "not_learned = pd.read_csv(os.path.join(data_dir,'not_learned.csv'))\n",
    "not_learned_index = not_learned['not_learned']\n",
    "\n",
    "dirs = [learned_index, not_learned_index]\n",
    "names = ['learned', 'not_learned']\n",
    "shapes = [(len(learned_index),96,96,3),(len(not_learned_index),96,96,3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlengths(dirs):\n",
    "    lengths = []\n",
    "    shapes = []\n",
    "    for d in dirs:\n",
    "        with h5py.File(d, 'r') as hdf:\n",
    "            lengths.append(len(hdf['x']))\n",
    "            shapes.append(hdf['x'].shape)\n",
    "    return np.array(lengths), shapes\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "def getDataSample(data_dir, a):\n",
    "    with h5py.File(data_dir, 'r') as hdf:\n",
    "        data = []\n",
    "        for i in a:\n",
    "            data.append(np.array(list(hdf['x'][i])))\n",
    "        return np.array(data)\n",
    "    \n",
    "def getlbls(data_dir, a):\n",
    "    with h5py.File(data_dir, 'r') as hdf:\n",
    "        data = []\n",
    "        for i in a:\n",
    "            data.append(np.array(list(hdf['y'][i])))\n",
    "        return np.array(data)\n",
    "\n",
    "    \n",
    "def new_trainin_data_set(dirs, names, shapes):\n",
    "    #create dir if not exists\n",
    "    saving_dir = './data/'\n",
    "    if(not os.path.exists(saving_dir)):\n",
    "        os.mkdir(saving_dir)\n",
    "        \n",
    "    for i in range(len(dirs)):\n",
    "        #set path\n",
    "        path = os.path.join(saving_dir, names[i]+\"_x.h5\")\n",
    "        path2 = os.path.join(saving_dir, names[i]+\"_y.h5\")\n",
    "        \n",
    "        #create empty dataset\n",
    "        h5f = h5py.File(path, 'w')\n",
    "        h5f.create_dataset(\"x\", shapes[i], dtype='uint8')\n",
    "        h5f.close()\n",
    "        \n",
    "        h5f = h5py.File(path2, 'w')\n",
    "        h5f.create_dataset(\"y\", (len(dirs[i]),1,1,1), dtype='uint8')\n",
    "        h5f.close()\n",
    "        \n",
    "        \n",
    "        half = int(len(dirs[i])/2)\n",
    "        \n",
    "        with h5py.File(path, 'r') as hdf:\n",
    "            print(\"path = {}, length = {}, shape = {}\".format(path, len(hdf['x']), hdf['x'].shape))\n",
    "            \n",
    "        with h5py.File(path2, 'r') as hdf:\n",
    "            print(\"path = {}, length = {}, shape = {}\".format(path2, len(hdf['y']), hdf['y'].shape))\n",
    "            \n",
    "            \n",
    "        for j in range(2):\n",
    "            print(\"j = {}\".format(j))\n",
    "            #get half of the data\n",
    "            if j == 0:\n",
    "                data = getDataSample(train_dir_x, dirs[i][:half])\n",
    "                print('data',data.shape)\n",
    "                with h5py.File(path, 'a') as hf:\n",
    "                    hf[\"x\"][:half] = data\n",
    "                    \n",
    "                lbls = getlbls(train_dir_y, dirs[i][:half])\n",
    "                print('lbls',lbls.shape)\n",
    "                with h5py.File(path2, 'a') as hf:\n",
    "                    hf[\"y\"][:half] = lbls  \n",
    "                    \n",
    "                    \n",
    "            else: \n",
    "                data = getDataSample(train_dir_x, dirs[i][half:])\n",
    "                print('data',data.shape)\n",
    "                with h5py.File(path, 'a') as hf:\n",
    "                    hf[\"x\"][half:] = data\n",
    "                    \n",
    "                lbls = getlbls(train_dir_y, dirs[i][half:])\n",
    "                print('lbls',lbls.shape)\n",
    "                with h5py.File(path2, 'a') as hf:\n",
    "                    hf[\"y\"][half:] = lbls\n",
    "\n",
    "          \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path = ./data/learned_x.h5, length = 235211, shape = (235211, 96, 96, 3)\n",
      "path = ./data/learned_y.h5, length = 235211, shape = (235211, 1, 1, 1)\n",
      "j = 0\n",
      "data (117605, 96, 96, 3)\n",
      "lbls (117605, 1, 1, 1)\n",
      "j = 1\n",
      "data (117606, 96, 96, 3)\n",
      "lbls (117606, 1, 1, 1)\n",
      "path = ./data/not_learned_x.h5, length = 26933, shape = (26933, 96, 96, 3)\n",
      "path = ./data/not_learned_y.h5, length = 26933, shape = (26933, 1, 1, 1)\n",
      "j = 0\n",
      "data (13466, 96, 96, 3)\n",
      "lbls (13466, 1, 1, 1)\n",
      "j = 1\n",
      "data (13467, 96, 96, 3)\n",
      "lbls (13467, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "new_trainin_data_set(dirs, names, shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
